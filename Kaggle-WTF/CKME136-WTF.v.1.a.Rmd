---
title: "CKME136-WTF.v.1"
author: "Justiono Putro"
date: "October 21, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(warn = -1)
```

##Installed packages
install.packages("tseries")
install.packages("tidyr")
install.packages("dplyr")
install.packages("data.table")
install.packages("ggplot2")
install.packages("forecast")
install.packages('lubridate')
install.packages('fpp')
install.packages('prophet')
install.packages('MLmetrics')

##Load libraries
```{r echo=TRUE}
library(data.table)
library(tseries)
library(dplyr)
library(tidyr)
library(ggplot2)
library(lubridate)
library(forecast)
library(fpp)
library(prophet)
library(MLmetrics)
```

##Create functions
###Function to combine forecasts with (1) equal weight and (2) variance-based optimal weight.
### v = variance. fc = forecasted values
```{r echo=TRUE}
f.fcCombined1 <- function(fc1, fc2, fc3){ 
  fcc1 <- (fc1+fc2+fc3)/3
  return (fcc1) 
}

f.fcCombined2 <- function(fc1, fc2, fc3, v1, v2, v3){ 
  fcc2 <- ((v2+v3)/(v1+v2+v3))*fc1+((v1+v3)/(v1+v2+v3))*fc2+((v1+v2)/(v1+v2+v3))*fc3
  return (fcc2) 
}

```

###Function to calculate Mean Absolute Squared Error loss (MASE). f = vector with forecasts, y = vector with actuals
```{r echo=TRUE}
f.MASE <- function(f,y) {
  if(length(f)!=length(y)){ stop("Vector length is not equal") }
  n <- length(f)
  return(mean(abs((y - f) / ((1/(n-1)) * sum(abs(y[2:n]-y[1:n-1]))))))
}
```

###Function to calculate Symmetric Mean Absolute Percentage Error loss (SMAPE). Input: actual and predicted values
```{r echo=TRUE}
f.SMAPE <- function(act, pred){ 
  sm <- 200 * abs(act - pred) / (abs(act) + abs(pred)) # normal formula
  sm <- ifelse(is.na(act), NA, sm)                     # omit if act is NA
  sm <- ifelse(is.na(pred) & !is.na(act), 200, sm)     # max error if pred is NA and act is available
  sm <- ifelse(pred==0 & act==0, 0, sm)                # perfect (arbitrary 0/0=0)
  smape <- mean(sm, na.rm = TRUE)
  return (smape) 
}
```

## Read data
```{r echo=TRUE}
setwd("C:\\JP_TEMP\\CKME136")
dt.data <- fread("train_2.csv")

#require(RCurl)
#dt.data <- fread(text=getURL("https://github.com/Justiono/Kaggle.git/train_2.csv"))
```

## Exploratory data analysis 
```{r echo=TRUE}
# Dimension of dataset --> # of rows (website) x # of columns (daily visits/day)
c(nrow(dt.data),ncol(dt.data))

# View data attributes
dt.data %>% colnames() %>% head(15)
dt.data %>% colnames() %>% tail(5)

# Find out a portion of missing values compared to all data (%)
sum(is.na(dt.data))/((ncol(dt.data)-1)*nrow(dt.data))

# The number of data series with missing values for each row, ordered by number of missing NAs
dt.dataNA <- cbind((dt.data[!complete.cases(dt.data),][,1]),(as.data.table(rowSums(is.na(dt.data[!complete.cases(dt.data),])),row.names = NULL)))
setnames(dt.dataNA, c("Page","NA_Count"))

dt.dataNA <- arrange(dt.dataNA, desc(NA_Count))
dt.dataNA[1:10,]

dataNA_tmp <- dt.dataNA[1:10,1]
dt.dataNA_top10 <- dt.data[dt.data$Page %in% dataNA_tmp,]
dt.dataNA_top10[,c(1:3,801:804)]
```

# For the forecasting analysis, I selected top 10 pages with the highest number of page visits.
```{r echo=TRUE}
dt.data_tmp <- data.frame(dt.data$Page)
dt.data_tmp$sum = rowSums(dt.data[,2:804], na.rm = TRUE)
data_tmp <- arrange(dt.data_tmp, desc(sum))[1:10,1]
head(arrange(dt.data_tmp, desc(sum))[1:10,])
dt.data_top10 <- dt.data[dt.data$Page %in% data_tmp,]
```

```{r echo=TRUE}

```

```{r echo=TRUE}

```

```{r echo=TRUE}

```

```{r echo=TRUE}

```

```{r echo=TRUE}

```

```{r echo=TRUE}

```

```{r echo=TRUE}

```

```{r echo=TRUE}
options(warn = 0)
```
